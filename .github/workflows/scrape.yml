name: 1. Scrape Websites

on:
  # Run every 6 hours
  schedule:
    - cron: '0 */6 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      company_filter:
        description: 'Company name filter (optional)'
        required: false
        type: string
      force_scrape:
        description: 'Force re-scrape even if no changes detected'
        required: false
        type: boolean
        default: false
      use_three_db:
        description: 'Use three-database architecture'
        required: false
        type: boolean
        default: true
      cascade:
        description: 'Trigger next workflow in chain'
        required: false
        type: boolean
        default: true
  
  # Allow being called by other workflows
  workflow_call:
    inputs:
      cascade:
        description: 'Trigger next workflow in chain'
        required: false
        type: boolean
        default: false  # Different default for when called by full-monitor
    outputs:
      run_id:
        description: 'The workflow run ID'
        value: ${{ jobs.scrape-websites.outputs.run_id }}

# Prevent concurrent runs
concurrency:
  group: scrape-workflow
  cancel-in-progress: false

env:
  NODE_ENV: production
  USE_THREE_DB: ${{ inputs.use_three_db || 'true' }}

jobs:
  scrape-websites:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Increased from 30 to handle all 52 companies
    
    outputs:
      run_id: ${{ github.run_id }}
    
    permissions:
      contents: write
      actions: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history to allow proper rebasing
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        run: |
          cd github-actions-backend
          # Use npm install instead of npm ci to handle package-lock.json mismatches
          npm install --omit=dev
      
      - name: Install Puppeteer browsers
        run: |
          cd github-actions-backend
          npx puppeteer browsers install chrome
      
      - name: Initialize database (three-db architecture)
        if: ${{ env.USE_THREE_DB == 'true' }}
        run: |
          cd github-actions-backend
          
          # Run the three-database initialization
          echo "üìä Initializing three-database architecture..."
          node scripts/init-db-three.js
      
      - name: Initialize database (legacy)
        if: ${{ env.USE_THREE_DB != 'true' }}
        run: |
          cd github-actions-backend
          
          # Check if database exists in repository
          if [ -f data/monitor.db ]; then
            echo "‚úÖ Database found in repository"
          else
            echo "üìä Database not found, initializing..."
            mkdir -p data
            node scripts/init-db.js
            echo "‚úÖ Database initialized with 52 companies"
          fi
      
      - name: Run intelligent scraper
        run: |
          cd github-actions-backend
          
          # Add company filter if provided
          if [ -n "${{ inputs.company_filter }}" ]; then
            echo "üéØ Filtering for company: ${{ inputs.company_filter }}"
            # TODO: Add company filter support to scraper
          fi
          
          # Run scraper with timeout protection (increased to 45 minutes)
          timeout 45m node scraper-wrapper.js || {
            echo "‚ö†Ô∏è Scraper timeout after 45 minutes"
            echo "üí° Consider running with company_filter to process in smaller batches"
            exit 1
          }
        env:
          GITHUB_ACTIONS: 'true'
          FORCE_SCRAPE: ${{ inputs.force_scrape }}
      
      # REMOVED: Markdown conversion - this belongs in process.yml
      
      - name: Upload database backup (three-db)
        if: ${{ env.USE_THREE_DB == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: scraper-databases-${{ github.run_id }}
          path: |
            github-actions-backend/data/raw_content.db
            github-actions-backend/data/intelligence.db
          retention-days: 7
      
      - name: Upload database backup (legacy)
        if: ${{ env.USE_THREE_DB != 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: scraper-database-${{ github.run_id }}
          path: github-actions-backend/data/monitor.db
          retention-days: 7
      
      - name: Create scrape summary
        run: |
          cd github-actions-backend
          mkdir -p ../api-data
          echo "{
            \"workflow\": \"scrape\",
            \"run_id\": \"${{ github.run_id }}\",
            \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)\",
            \"status\": \"completed\",
            \"use_three_db\": ${{ env.USE_THREE_DB }}
          }" > ../api-data/last-scrape.json
      
      - name: Commit database changes (three-db)
        if: ${{ env.USE_THREE_DB == 'true' }}
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # First, show current git status
          echo "üìã Current git status:"
          git status
          
          # Clean up any unwanted files (but preserve our databases)
          echo "üßπ Cleaning up workspace..."
          # Remove SQLite temporary files if they exist
          find . -name "*.db-wal" -o -name "*.db-shm" | xargs rm -f || true
          # Remove node_modules that might have been created
          rm -rf node_modules || true
          
          # Stash any remaining uncommitted changes to ensure clean state
          echo "üì¶ Stashing any uncommitted changes..."
          git stash push -m "Temporary stash during workflow" || true
          
          # Add the databases and scrape status
          git add -f github-actions-backend/data/raw_content.db || true
          git add -f github-actions-backend/data/intelligence.db || true
          git add api-data/last-scrape.json || true
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
            git stash pop || true  # Restore stashed changes if any
          else
            # Commit the changes
            git commit -m "üï∑Ô∏è Update scraped content (three-db) - $(date -u +%Y-%m-%d\ %H:%M:%S\ UTC)"
            
            # Function to retry git push with exponential backoff
            push_with_retry() {
              local max_attempts=5
              local attempt=1
              local wait_time=1
              
              while [ $attempt -le $max_attempts ]; do
                echo "üîÑ Attempt $attempt/$max_attempts to push changes..."
                
                # Pull latest changes and rebase our commit on top
                git fetch origin main
                git rebase origin/main || {
                  echo "‚ùå Rebase failed, trying merge strategy..."
                  git rebase --abort 2>/dev/null || true
                  git pull origin main --no-rebase --strategy=ours || {
                    echo "‚ùå Merge failed, resetting and retrying"
                    git reset --hard HEAD~1
                    git pull origin main
                    # Re-add and commit our changes
                    git add -f github-actions-backend/data/raw_content.db || true
                    git add -f github-actions-backend/data/intelligence.db || true
                    git add api-data/last-scrape.json || true
                    git commit -m "üï∑Ô∏è Update scraped content (three-db) - $(date -u +%Y-%m-%d\ %H:%M:%S\ UTC)"
                  }
                }
                
                # Try to push
                if git push origin main; then
                  echo "‚úÖ Successfully pushed changes!"
                  return 0
                else
                  echo "‚ùå Push failed"
                  
                  if [ $attempt -lt $max_attempts ]; then
                    echo "‚è≥ Waiting ${wait_time}s before retry..."
                    sleep $wait_time
                    wait_time=$((wait_time * 2))
                    attempt=$((attempt + 1))
                  else
                    echo "‚ùå All push attempts failed"
                    return 1
                  fi
                fi
              done
            }
            
            # Push the changes with retry
            push_with_retry || {
              echo "‚ö†Ô∏è  Failed to push changes after multiple attempts"
              echo "‚ö†Ô∏è  Scraping completed but changes couldn't be pushed"
              echo "‚ö†Ô∏è  Manual intervention may be required"
              exit 1  # Fail since scraping data is critical
            }
            
            # Clean up stash if any
            git stash pop || true
          fi
      
      - name: Commit database changes (legacy)
        if: ${{ env.USE_THREE_DB != 'true' }}
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # First, show current git status
          echo "üìã Current git status:"
          git status
          
          # Clean up any unwanted files (but preserve our databases)
          echo "üßπ Cleaning up workspace..."
          # Remove SQLite temporary files if they exist
          find . -name "*.db-wal" -o -name "*.db-shm" | xargs rm -f || true
          # Remove node_modules that might have been created
          rm -rf node_modules || true
          
          # Stash any remaining uncommitted changes to ensure clean state
          echo "üì¶ Stashing any uncommitted changes..."
          git stash push -m "Temporary stash during workflow" || true
          
          # Add the database and scrape status
          git add -f github-actions-backend/data/monitor.db || true
          git add api-data/last-scrape.json || true
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
            git stash pop || true  # Restore stashed changes if any
          else
            # Commit the changes
            git commit -m "üï∑Ô∏è Update scraped content - $(date -u +%Y-%m-%d\ %H:%M:%S\ UTC)"
            
            # Function to retry git push with exponential backoff
            push_with_retry() {
              local max_attempts=5
              local attempt=1
              local wait_time=1
              
              while [ $attempt -le $max_attempts ]; do
                echo "üîÑ Attempt $attempt/$max_attempts to push changes..."
                
                # Pull latest changes and rebase our commit on top
                git fetch origin main
                git rebase origin/main || {
                  echo "‚ùå Rebase failed, trying merge strategy..."
                  git rebase --abort 2>/dev/null || true
                  git pull origin main --no-rebase --strategy=ours || {
                    echo "‚ùå Merge failed, resetting and retrying"
                    git reset --hard HEAD~1
                    git pull origin main
                    # Re-add and commit our changes
                    git add -f github-actions-backend/data/monitor.db || true
                    git add api-data/last-scrape.json || true
                    git commit -m "üï∑Ô∏è Update scraped content - $(date -u +%Y-%m-%d\ %H:%M:%S\ UTC)"
                  }
                }
                
                # Try to push
                if git push origin main; then
                  echo "‚úÖ Successfully pushed changes!"
                  return 0
                else
                  echo "‚ùå Push failed"
                  
                  if [ $attempt -lt $max_attempts ]; then
                    echo "‚è≥ Waiting ${wait_time}s before retry..."
                    sleep $wait_time
                    wait_time=$((wait_time * 2))
                    attempt=$((attempt + 1))
                  else
                    echo "‚ùå All push attempts failed"
                    return 1
                  fi
                fi
              done
            }
            
            # Push the changes with retry
            push_with_retry || {
              echo "‚ö†Ô∏è  Failed to push changes after multiple attempts"
              echo "‚ö†Ô∏è  Scraping completed but changes couldn't be pushed"
              echo "‚ö†Ô∏è  Manual intervention may be required"
              exit 1  # Fail since scraping data is critical
            }
            
            # Clean up stash if any
            git stash pop || true
          fi
      
      - name: Trigger Process workflow
        if: inputs.cascade == true
        uses: actions/github-script@v7
        with:
          script: |
            const result = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'process.yml',
              ref: 'main',
              inputs: {
                trigger_source: 'scrape-cascade',
                run_id: '${{ github.run_id }}',
                cascade: 'true'  // Pass cascade through
              }
            });
            console.log(`‚úÖ Triggered Process workflow`);
      
      # Cascade parameter system implemented
      # Manual runs (cascade: true) trigger the next workflow
      # Full-monitor runs (cascade: false) prevent duplicates
